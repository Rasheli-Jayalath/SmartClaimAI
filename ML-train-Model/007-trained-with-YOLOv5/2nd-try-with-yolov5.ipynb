{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b4c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import the necessary libraries\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6768262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the data directories and classes\n",
    "\n",
    "data_dir = '../dataset/data1a'\n",
    "train_dir = os.path.join(data_dir, 'training')\n",
    "valid_dir = os.path.join(data_dir, 'validation')\n",
    "\n",
    "# Define the classes\n",
    "classes = ['No Damage', 'Damage']\n",
    "damage_classes = ['00-minor', '01-moderate', '02-severe']\n",
    "location_classes = ['00-front', '01-rear', '02-side']\n",
    "type_classes = ['00-damage', '01-whole']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bc2a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Define the data transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7018544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Define the data loaders\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform_train)\n",
    "valid_dataset = datasets.ImageFolder(valid_dir, transform=transform_valid)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c040b459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from torch) (1.9)\n",
      "Requirement already satisfied: numpy in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rasheli\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Collecting git+https://github.com/ultralytics/yolov5.git\n",
      "  Cloning https://github.com/ultralytics/yolov5.git to c:\\users\\rasheli\\appdata\\local\\temp\\pip-req-build-kxei7xv3\n",
      "  Resolved https://github.com/ultralytics/yolov5.git to commit ff6a9ac842f3a09941ac3dca5355cfa896b5f5d7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/ultralytics/yolov5.git 'C:\\Users\\Rasheli\\AppData\\Local\\Temp\\pip-req-build-kxei7xv3'\n",
      "ERROR: File \"setup.py\" not found for legacy project git+https://github.com/ultralytics/yolov5.git.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Define the model architecture\n",
    "\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install git+https://github.com/ultralytics/yolov5.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16c5585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-4-24 Python-3.9.7 torch-2.0.0+cpu CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\Rasheli\\.cache\\torch\\hub\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5m.pt', verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a6de184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define the loss function and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf30c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7: Train the model\n",
    "\n",
    "#Step 7: Train the model\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    num_classes = len(classes)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.view(-1, num_classes, 5 + num_anchors)\n",
    "            outputs = outputs.permute(0, 2, 1).contiguous()\n",
    "            outputs = outputs.view(-1, num_classes)\n",
    "            labels = labels.view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "num_anchors = 32  # replace 3 with the appropriate value for your use case\n",
    "\n",
    "# def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "#     for epoch in range(num_epochs):\n",
    "#         train_loss = 0.0\n",
    "#         for inputs, labels in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             outputs = outputs.view(-1, num_classes, 5 + num_anchors)\n",
    "#             outputs = outputs.permute(0, 2, 1).contiguous()\n",
    "#             outputs = outputs.view(-1, num_classes)\n",
    "#             labels = labels.view(-1)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "#         train_loss = train_loss / len(train_loader.dataset)\n",
    "#         print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "\n",
    "\n",
    "# def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "#     for epoch in range(num_epochs):\n",
    "#         train_loss = 0.0\n",
    "#         for inputs, labels in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "#         train_loss = train_loss / len(train_loader.dataset)\n",
    "#         print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41eeced2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 2, 37]' is invalid for input of size 8396640",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10688/2089947670.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10688/2476485615.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnum_anchors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[-1, 2, 37]' is invalid for input of size 8396640"
     ]
    }
   ],
   "source": [
    "train_model(model, criterion, optimizer, num_epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29725bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Save the trained model\n",
    "\n",
    "torch.save(model.state_dict(), 'vehicle_damage_detection.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f2dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Test the model\n",
    "\n",
    "def test_model(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        print('Accuracy on the validation set: {:.2%}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e79869",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c4cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 10: Make predictions\n",
    "\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image_tensor = transform(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    output = model(input)\n",
    "    index = output.data.numpy().argmax()\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015ea27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = predict_image('test_image.jpg')\n",
    "if index == 0:\n",
    "    print('The vehicle is not damaged')\n",
    "else:\n",
    "    print('The vehicle is damaged')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26724743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image_tensor = transform(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    output = model(input)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    return predicted.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769c747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c5e30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
